{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfa6e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def heuristic(a, b):\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "def a_star_search(grid, start, goal):\n",
    "    start = tuple(start)\n",
    "    goal = tuple(goal)\n",
    "\n",
    "    neighbors = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # Right, Down, Left, Up\n",
    "    close_set = set()\n",
    "    came_from = {}\n",
    "    gscore = {start: 0}\n",
    "    fscore = {start: heuristic(start, goal)}\n",
    "    open_heap = []\n",
    "\n",
    "    heapq.heappush(open_heap, (fscore[start], start))\n",
    "    \n",
    "    while open_heap:\n",
    "        current = heapq.heappop(open_heap)[1]\n",
    "\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            return path[::-1]\n",
    "\n",
    "        close_set.add(current)\n",
    "        for i, j in neighbors:\n",
    "            neighbor = current[0] + i, current[1] + j\n",
    "            tentative_g_score = gscore[current] + heuristic(current, neighbor)\n",
    "            if 0 <= neighbor[0] < len(grid) and 0 <= neighbor[1] < len(grid[0]) and grid[neighbor[0]][neighbor[1]] == 1:\n",
    "                if neighbor in close_set and tentative_g_score >= gscore.get(neighbor, 0):\n",
    "                    continue\n",
    "                \n",
    "                if tentative_g_score < gscore.get(neighbor, 0) or neighbor not in [i[1] for i in open_heap]:\n",
    "                    came_from[neighbor] = current\n",
    "                    gscore[neighbor] = tentative_g_score\n",
    "                    fscore[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                    heapq.heappush(open_heap, (fscore[neighbor], neighbor))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return []  # No path found\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "921e117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class RandGridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, size=10):\n",
    "        self.size = size\n",
    "        self.window_size = 512\n",
    "        self.action_space = spaces.Discrete(4)  # Up, down, left, right\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=np.int64),\n",
    "            \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=np.int64),\n",
    "        })\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self._grid, self._agent_location, self._target_location = self.generate_grid()\n",
    "        \n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),\n",
    "            1: np.array([0, 1]),\n",
    "            2: np.array([-1, 0]),\n",
    "            3: np.array([0, -1]),\n",
    "        }\n",
    "\n",
    "    def generate_grid(self):\n",
    "        grid = np.ones((self.size, self.size), dtype=int)  # Open grid\n",
    "        start, goal = self._initialize_start_target(grid)\n",
    "\n",
    "        # Add obstacles, ensuring there is a path from start to goal\n",
    "        obstacles_to_add = random.randint(1, self.size * self.size // 4)\n",
    "        while obstacles_to_add > 0:\n",
    "            obstacle = (random.randint(0, self.size - 1), random.randint(0, self.size - 1))\n",
    "            if obstacle != start and obstacle != goal and grid[obstacle] == 1:\n",
    "                # Temporarily add the obstacle\n",
    "                grid[obstacle] = 0\n",
    "                path = a_star_search(grid, start, goal)\n",
    "                if not path:  # No path found, remove the obstacle\n",
    "                    grid[obstacle] = 1\n",
    "                else:\n",
    "                    obstacles_to_add -= 1  # Obstacle successfully added\n",
    "\n",
    "        return grid, start, goal\n",
    "\n",
    "    def _initialize_start_target(self, grid):\n",
    "        # Initialize start point\n",
    "        while True:\n",
    "            start = (random.randint(0, self.size - 1), random.randint(0, self.size - 1))\n",
    "            if grid[start] == 1:  # Ensure start is not an obstacle\n",
    "                break\n",
    "\n",
    "        # Initialize goal point\n",
    "        while True:\n",
    "            goal = (random.randint(0, self.size - 1), random.randint(0, self.size - 1))\n",
    "            if grid[goal] == 1 and goal != start:  # Ensure goal is not an obstacle and not the start\n",
    "                break\n",
    "\n",
    "        return start, goal\n",
    "\n",
    "    # Implement other methods like reset, step, render, _get_obs, _get_info, etc.\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                np.array(self._agent_location) - np.array(self._target_location), ord=1\n",
    "            )\n",
    "        }\n",
    "    def get_agent_location(self):\n",
    "        return self._agent_location\n",
    "    \n",
    "    def test_method(self):\n",
    "        return \"Test successful\"\n",
    "    \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Regenerate the grid and the start/goal locations\n",
    "        self._grid, self._agent_location, self._target_location = self.generate_grid()\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "    def step(self, action):\n",
    "        # Map the action to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "\n",
    "        # Calculate the proposed new position based on the action\n",
    "        proposed_new_position = np.array(self._agent_location) + direction\n",
    "\n",
    "        # Use np.clip to ensure the new position doesn't go out of bounds\n",
    "        new_position = np.clip(proposed_new_position, 0, self.size - 1)\n",
    "\n",
    "        # Calculate the Manhattan distance to the goal before and after the move\n",
    "        old_distance = np.sum(np.abs(np.array(self._target_location) - np.array(self._agent_location)))\n",
    "        new_distance = np.sum(np.abs(np.array(self._target_location) - new_position))\n",
    "\n",
    "        # Initialize reward\n",
    "        reward = -2  # Penalty for every step\n",
    "\n",
    "        # Check if the new position is an obstacle or free space\n",
    "        if self._grid[tuple(new_position)] == 1 and not np.array_equal(new_position, self._agent_location):\n",
    "            # Update the agent's position only if new position is different from the current\n",
    "            self._agent_location = new_position.tolist()  # convert array back to list to keep the data type consistent\n",
    "            if new_distance < old_distance:\n",
    "                # Positive reward for moving closer to the goal\n",
    "                reward += 5\n",
    "        elif np.array_equal(new_position, self._agent_location):\n",
    "            # Agent hit an obstacle or the bounds of the grid and did not move, do not update the position\n",
    "            pass\n",
    "        else:\n",
    "            # Negative reward for hitting an obstacle\n",
    "            reward -= 0.002\n",
    "\n",
    "        # Check if the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        if terminated:\n",
    "            # Positive reward for reaching the goal\n",
    "            reward += 10\n",
    "\n",
    "        # Get the current state observation and info about the environment\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, False, info\n",
    "\n",
    "    \n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size, self.window_size)\n",
    "            )\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )  # The size of a single grid square in pixels\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location,\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self._agent_location + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    " \n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad43a6a",
   "metadata": {},
   "source": [
    "def step(self, action):\n",
    "        # Map the action to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "\n",
    "        # Calculate the proposed new position based on the action\n",
    "        new_position = self._agent_location + direction\n",
    "\n",
    "        # Use np.clip to ensure the new position doesn't go out of bounds\n",
    "        new_position = np.clip(new_position, 0, self.size - 1)\n",
    "\n",
    "        reward = -0.01  # Small negative reward for each step taken\n",
    "\n",
    "        # Check if the new position is an obstacle or free space\n",
    "        if self._grid[tuple(new_position)] == 1:\n",
    "            self._agent_location = new_position  # Update the agent's position\n",
    "        else:\n",
    "            reward -= 1  # Large negative reward for hitting an obstacle\n",
    "\n",
    "        # Check if the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "\n",
    "        # Reward is given only if the target is reached\n",
    "        if terminated:\n",
    "            reward = 1  # Positive reward for reaching the goal\n",
    "\n",
    "        # Get the current state observation and info about the environment\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        # Render the environment if it's set to human mode\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated, False, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a42cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfde3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35feb1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
